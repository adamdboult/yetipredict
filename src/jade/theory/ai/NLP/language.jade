extends ./subSubTemplate.jade
block subSubTitle
	h1
		b Probabilistic language models
block subSubContent
	h3
		b Introduction 
	p Probabilistic language models can predict future words given a history of words.
	p This can be used for predictive text. For example if a user types "Did you call your" we may want to estimate the probability that the next word is "child".
	p We can state this problem:
	p \(P(child|did\ you\ call\ your)\)
	p By definition this is:
	p \(P(child|did\ you\ call\ your)= \frac{P(did\ you\ call\ your\ child)}{P(did\ you\ call\ your)}\)
	p We can estimate each of these:
	p \(P(did\ you\ call\ your\ child)=\frac{|did\ you\ call\ your\ child|}{|5\ word\ sentences|}\)
	p \(P(did\ you\ call\ your)=\frac{|did\ you\ call\ your|}{|4\ word\ sentences|}\)
	h3
		b Data requirements
	p This needs a large corpus, which may not be practical.
	p Additionallly, the words must be indexed, and not simply stored as a bag of words.
	h3
		b Decomposition
	p We can decompose the probabilities using the chain rule.
	p \(P(did\ you\ call\ your\ child)=P(did)P(you|did)...P(child|did\ you\ call\ your)\)
	p \(P(w_1,...,w_k)= \prod_k p(w_k|w_1,...,w_{k-1})\)
	h3
		b N-grams
	p We can simplify the decomposition using the Markov assumption:
	p \(P(w_k|w_1,...,w_{k-1})=P(w_k|w_{k-1})\)
	p This is a \(1\)-gram.
	p We can do this for \(n\) words back. This is an \(n\)-gram.
	h3
		b Smoothing
	p We can use smoothing to address small corpuses.
	p \(P(did\ you\ call\ your\ child)=\frac{|did\ you\ call\ your\ child|+1}{|5\ word\ sentences|+V}\)
	p \(P(did\ you\ call\ your)=\frac{|did\ you\ call\ your|+1}{|4\ word\ sentences|+V}\)
	p For some value \(V\).
	h3
		b Perplexity
	p We can compare probabilistic language models using perplexity.
	p We can then choose the model with the lowest perplexity.
	p \(perplexity(w_1, w_2, ..., w_n)=P(w_1, w_2, ..., w_n)^{-\frac{1}{n}}\)
	p We can expand this:
	p \(perplexity(w_1, w_2, ..., w_n)=\prod_i P(w_i| w_1, ..., w_{i-1})^{-\frac{1}{n}}\)
	p Depending on which n-gram we use we can then simplify this.

