extends ./MDP/subSubTemplate.jade
block subSubContent
	h3
		b Stochastic environments
	p
		a(href="./MDP/chain") Markov chain recap
	p
		a(href="./MDP/value") The value function
	h3
		b Markov Decision Processes (MDPs)
	p
		a(href="./MDP/MDP") Markov Decision Processes (MDPs)
	p
		a(href="./MDP/policies") Policies
	p
		a(href="./MDP/valuePolicy") The value function of a policy
	h3
		b Identifying policies
	p
		a(href="./MDP/linear") Solving Markov Decision Processes with linear programming
	p
		a(href="./MDP/bellman") The Bellman equation for Markov Decision Processes
	p
		a(href="./MDP/policyIteration") Policy iteration
	p
		a(href="./MDP/valueIteration") Value iteration
	h3
		b Markov Decision Processes with infinite states
	p
		a(href="./MDP/infinite") Markov Decision Processes with infinite states

