extends ./subSubTemplate.jade
block subSubTitle
	h1
		b Markov Decision Processes (MDPs)
block subSubContent
	h3
		b Introduction
	p 
	h3
		b Actions
	p In a MDP the agent can choose an action in each state. The action affects the transition matrix.
	p This means that the rewards depends on the actions taken. We now have:
	ul
		li \(S\) - the state space
		li \(s_1\) - the initial state
		li \(A\) - the action space
		li \(P\) - the transition model
		li \(R\) - the reward distribution


