extends ./subSubTemplate.jade

block subSubContent
	h2
		b Optimisation
	p Given a function with inputs \(x\), what values of \(x\) maximise the function?
	p We explore constrained and unconstrained optimisation. The former is where restrictions are placed on vector \(x\), such as a budget constraint in economics.
	h3
		b Unconstrained optimisation
	p Find stationary points
	p Stationary points of a function are points where marginal changes do not have an impact on the value of the function. As a result they are either local maxima or minima.
	p We can identify these by taking partial derivatives of the function in question and identifying where this function is equal to zero.
	p $$u=f(x)$$
	p $$u_{x_i}=\frac{\delta f}{\delta x_i}=0$$
	p We can then solve this bundle of equations.
	p Find direction beyond stationary points
	p After identifying the vector \(x\) for these points we can then  determine whether or not the points are minima or maxima by  examining the second derivative at these points. If it is positive it is a local minima, and therefore not an optimal point. Points beyond these will be higher, and may be higher than any local maxima.
	p If a function is concave 
	h3
		b Constrained optimisation
	p Lagrangian
	p Rather than maximise \(f(x)\), we want to maximise \(f(x)\) subject to \(g(x)=0\), and possibly additional constraints. This is often used in economics where we want to maximise a utility function subject to budget constraints.
	p The form of such a function looks like:
	p $$\mathcal{L}(x,\lambda )=f(x)-\sum^m_k\lambda_k [g_k(x)-c_k]$$
	p We examine the stationary points for both vector \(x\) and \(\lambda \). By including the latter we ensure that these points are consistent with the budget constraint.
	p Interpretation of lambda value. Margina utility for income, if loosened.
	p If value of lambda <0 then not binding, constraint may not give optimal value.
	p Convexity if not binding.
	h3
		b Solving the Langrangian with one constraint
	p Our function is:
	p $$\mathcal{L}(x, \lambda )=f(x)-\lambda [g(x)-c]$$
	p p$$\mathcal{L}_{\lambda }= -[g(x)-c]$$
	p $$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\lambda \frac{\delta g}{\delta x_i}$$
	p Same for all \(x\).
	p $$\mathcal{L}_{x_j}=\frac{\delta f}{\delta x_j}-\lambda \frac{\delta g}{\delta x_j}$$
	p Find max where constrained:
	p $$\mathcal{L}_{x_i}=L_{x_j}=L_{\lambda}=0$$
	p $$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\lambda \frac{\delta g}{\delta x_i}=0$$
	p $$\lambda \frac{\delta g}{\delta x_i}=\frac{\delta f}{\delta x_i}$$
	p $$\lambda =\frac{\frac{\delta f}{\delta x_i}}{\frac{\delta g}{\delta x_i}}$$
	p True for all x so
	p $$\lambda =\frac{\frac{\delta f}{\delta x_j}}{\frac{\delta g}{\delta x_j}}$$
	p Finally, we can use the following in practical applications.
	p $$\frac{\frac{\delta f}{\delta x_i}}{\frac{\delta g}{\delta x_i}}=\frac{\frac{\delta f}{\delta x_j}}{\frac{\delta g}{\delta x_j}}$$
	p Solving the Langrangian with many constraints
	p $$\mathcal{L} (x,\lambda )=f(x)-\sum^m_k\lambda_k [g_k(x)-c_k]$$
	p $$\mathcal{L}_{\lambda_i }= -[g_i(x)-c_i]$$
	p $$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_i}$$
	p Same for all x:
	p $$\mathcal{L}_{x_j}=\frac{\delta f}{\delta x_j}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_j}$$
	p Find max where constrained:
	p $$\mathcal{L}_{x_i}=L_{x_j}=0$$
	p $$\mathcal{L}_{\lambda_k} L_{\lambda_l}=0$$
	p So
	p $$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_i}=0$$
	p $$\mathcal{L}_{x_j}=\frac{\delta f}{\delta x_j}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_j}=0$$
	p $$\frac{\delta f}{\delta x_i}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_i}=\frac{\delta f}{\delta x_j}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_j}$$
