extends ./subSubTemplate.jade

block subSubTitle
	h1
		b Descent algorithms

block subSubContent
	h3
		b What is gradient descent?
	p Rather than solve a normal equation, gradient descent takes the loss function, and takes the derivative of the loss function with respect to each parameter.
	p Small adjustments are then made to the parameters, in the direction of the steepest derivative, resulting in better parameters.

	p As derivative term gets smaller, convergance happens. The largest changes to the parametres occurs early on in the algorithm.


	p can stop if not lowering by much


	h3
		b Gradient descent and feature scaling
	p makes trajectory smoother, gets there faster
	p get things to -1<x<1 range

	h3
		b Local minima
	p Gradient descent is not guaratneed to arrive at a global minimum. For some loss functions, there will be multiple local minima, and gradient descent can end up in the wrong one.
	p Linear regression does not have this issue.
	p As a result, when we create functions with loss functions, convextity is very important. If the loss space is convex, then we will not get stuck in a local minima.
	h3
		b Batch gradient descent
	p := used to denote an update of variable. Used in programming, eg x=x+1.
	p $$\theta _j := \alpha \frac{\delta }{\delta \theta _j}J(\theta _0,\theta _1)$$
	p \(\alpha \) sets rate of descent.



	p theta 0 := theta 0 - alpha/m sum(h0(x) - y)
	p theta j := theta j - alpha/m sum(h0(x) - y)xj

	p can check if j theta increasing, means bad methodology, lower alpha


	p get run for x iterations,evaluate j(theta)

	p Can use matrices to do each step


	p can check convergence by checking cost over last 1000 or so, rather than all

	p smaller learning rate can get to better solution, as can circle drain for small samples

	p slowly decreasing learning rate can get better solutions
	p alpha = const1/(i + cost2)
