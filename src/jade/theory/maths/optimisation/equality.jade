extends ./subSubTemplate.jade

block subSubTitle
	h1
		b Equality constraints

block subSubContent
	h3
		b Constrained optimisation
	p Lagrangian
	p Rather than maximise \(f(x)\), we want to maximise \(f(x)\) subject to \(g(x)=0\), and possibly additional constraints. This is often used in economics where we want to maximise a utility function subject to budget constraints.
	p The form of such a function looks like:
	p $$\mathcal{L}(x,\lambda )=f(x)-\sum^m_k\lambda_k [g_k(x)-c_k]$$
	p We examine the stationary points for both vector \(x\) and \(\lambda \). By including the latter we ensure that these points are consistent with the budget constraint.
	p Interpretation of lambda value. Margina utility for income, if loosened.
	p If value of lambda <0 then not binding, constraint may not give optimal value.
	p Convexity if not binding.
	h3
		b Solving the Langrangian with one constraint
	p Our function is:
	p $$\mathcal{L}(x, \lambda )=f(x)-\lambda [g(x)-c]$$
	p p$$\mathcal{L}_{\lambda }= -[g(x)-c]$$
	p $$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\lambda \frac{\delta g}{\delta x_i}$$
	p Same for all \(x\).
	p $$\mathcal{L}_{x_j}=\frac{\delta f}{\delta x_j}-\lambda \frac{\delta g}{\delta x_j}$$
	p Find max where constrained:
	p $$\mathcal{L}_{x_i}=L_{x_j}=L_{\lambda}=0$$
	p $$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\lambda \frac{\delta g}{\delta x_i}=0$$
	p $$\lambda \frac{\delta g}{\delta x_i}=\frac{\delta f}{\delta x_i}$$
	p $$\lambda =\frac{\frac{\delta f}{\delta x_i}}{\frac{\delta g}{\delta x_i}}$$
	p True for all x so
	p $$\lambda =\frac{\frac{\delta f}{\delta x_j}}{\frac{\delta g}{\delta x_j}}$$
	p Finally, we can use the following in practical applications.
	p $$\frac{\frac{\delta f}{\delta x_i}}{\frac{\delta g}{\delta x_i}}=\frac{\frac{\delta f}{\delta x_j}}{\frac{\delta g}{\delta x_j}}$$
	p Solving the Langrangian with many constraints
	p $$\mathcal{L} (x,\lambda )=f(x)-\sum^m_k\lambda_k [g_k(x)-c_k]$$
	p $$\mathcal{L}_{\lambda_i }= -[g_i(x)-c_i]$$
	p $$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_i}$$
	p Same for all x:
	p $$\mathcal{L}_{x_j}=\frac{\delta f}{\delta x_j}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_j}$$
	p Find max where constrained:
	p $$\mathcal{L}_{x_i}=L_{x_j}=0$$
	p $$\mathcal{L}_{\lambda_k} L_{\lambda_l}=0$$
	p So
	p $$\mathcal{L}_{x_i}=\frac{\delta f}{\delta x_i}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_i}=0$$
	p $$\mathcal{L}_{x_j}=\frac{\delta f}{\delta x_j}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_j}=0$$
	p $$\frac{\delta f}{\delta x_i}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_i}=\frac{\delta f}{\delta x_j}-\sum^m_k\lambda_k \frac{\delta g_k}{\delta x_j}$$
	h3
		b More
	p We can add equality constraints to an optimisation problem.
	p Minimise \(f(x)\) subject to 
	p \(g_i(x)=0\) for \(i=1,â€¦,p\)
	p Consider a function, the Lagrangian:
	p \(\mathcal{L}(x, \lambda )=f(x) +\sum_{i=1}^p\lambda_ig_i(x)\)
	p By taking partial derivatives with respect to \(x\) and \(\lambda \), we can identify the critical points.
	p This forces the equality condition to hold, as the first order condition for \(lambda_i\) is one of the equality constraints.
	p If the constraints are mutually exclusive, for example \(y=x+1\) and \(y=x+2\) then these will not be solvable.
	p The values of the Lagrangian multipliers can have interpretations, depending on their formulation. If a constraint is of the format:
	p \(g_i(x)=m-h(x)\)
	p Then:
	p \(\mathcal{L}_m=\lambda_i \)
	p Here, \(lambda_i\) represents the impact of increasing \(m\).
