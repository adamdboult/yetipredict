extends ./subSubTemplate.jade

block subSubTitle
	h1
		b Determinants
block subSubContent
	h3
		b Recap
	p From invertible matrix section in endo
	h3
		b Introduction
	p A matrix can only be inverted if it can be created from a combination of elementary row operations.
	p How can we identify if a matrix is invertible? We want to create a scalar from the matrix which tells us if this possible. We can this scalar the determinant.
	p For a matrix \(A\) we label the determinant \(|A|\), or \(\det A\)
	p We propose \(|A|=0\) when the matrix is not invertible.
	p So how can we identify the function we need to undertake on the matrix?
	h3
		b New 1
	p We know that linear dependence results in determinants of \(0\).
	p We can model this as a function on the columns of the matrix.
	p \(\det M = \det ([M_1, ...,M_n)\)
	p If there is linear depednence, for example if two columns are the same then:
	p \(\det ([M_1,...,M_i,...,M_i,...,M_n])=0\)
	p Similarly, if there is a column of \(0\) then the determinant is \(0\).
	p \(\det ([M_1,...,0,...,M_n])=0\)
	h3
		b New 2
	p Show linear in addition
	p How can we identify the determinant of less simple matrices? We can use the multilinear form.
	p \(\sum c_i\mathbf M_i=\mathbf 0\)
	p Where \(\mathbf c \ne \mathbf 0\)
	p Or:
	p \(M\mathbf c=\mathbf 0\)
	h3
		b Rule 1: Columns of matrices can be the input to a multilinear form
	p A matrix can be shown in terms of its columns.
	p $$A=[v_1,...,v_n]$$
	p $$\det A=\det [v_1,...,v_n]$$

	p $$\det A=\sum_{k_1=1}^m...\sum_{k_n=1}\prod_{i=1}^ma_{ik_i}\det ([e_{k_1},...,e_{k_n}])$$
	h3
		b Multiplying a matrix by a constant multiplies the determinant by the same amount
	p If a whole row or columns is \(0\) then:
	p $$\det A=\det [v_1,...,v_i,...,v_n]$$
	p $$\det A'=\det [v_1,...,cv_i,...,v_n]$$

	p $$\det A=\det [v_1,...,v_i,...,v_n]$$
	p $$\det A'=\det [v_1,...,cv_i,...,v_n]$$
	p $$\det A'=c\det [v_1,...,v_i,...,v_n]$$
	p $$\det A'=c\det A$$
	p As a result, multiplying a column by \(0\) makes the determinant \(0\).
	p A matrix with a column of \(0\) therefore has determinant \(0\)
	h3
		b Rule 2: A matrix with equal columns has a determinant of \(0\).
	p $$A=[a_1,...,a_i,...,a_i,...,a_n]$$
	p $$D(A)=D([a_1,...,a_i,...,a_i,...,a_n])$$
	p We know from Result 3 that swapping columns reverses the sign. Reversing columns results in the same matrix, so the determinant must be unchanged.
	p $$D(A)=-D(A)$$
	p $$D(A)=0$$
	h3
		b Linear dependence
	p If a column is a linear combination of other columns, then the matrix cannot be inverted.
	p $$A=[a_1,...,\sum_{j\ne i}^{n}c_ja_j,...,a_n]$$
	p $$\det A=\det ([v_1,...,\sum_{j\ne i}^{n}c_jv_j,...,v_n])$$
	p $$\det A=\sum_{j\ne i}^{n}c_j\det ([v_1,...,v_j,...,v_n])$$
	p $$\det A=\sum_{j\ne i}^{n}c_j\det ([v_1,...,v_j,,...,v_j,...,v_n])$$
	p As there is a repeating vector:
	p \(\det A=0\)
	h3
		b Swapping columns multiplies the determinant by \(-1\)
	p 
	p $$A=[v_1,...,v_i+v_j,...,v_i+v_j,...,v_n]$$
	p We know.
	p $$\det A=0$$
	p $$\det A=\det ([a_1,...,a_i,...,a_i,...,a_n])+\det([a_1,...,a_i,...,a_j,...,a_n])+\det([a_1,...,a_j,...,a_i,...,a_n])+\det([a_1,...,a_j,...,a_j,...,a_n])$$
	p So:
	p $$\det ([a_1,...,a_i,...,a_i,...,a_n])+\det ([a_1,...,a_i,...,a_j,...,a_n])+\det([a_1,...,a_j,...,a_i,...,a_n])+\det([a_1,...,a_j,...,a_j,...,a_n])=0$$
	p As \(2\) of these have equal columns these are equal to \(0\).
	p $$\det ([a_1,...,a_i,...,a_j,...,a_n])+\det ([a_1,...,a_j,...,a_i,...,a_n])=0$$
	p $$\det ([a_1,...,a_i,...,a_j,...,a_n])=-\det ([a_1,...,a_j,...,a_i,...,a_n])$$
	h3
		b Calculating the determinant
	p We have
	p $$\det A=\sum_{k_1=1}^m...\sum_{k_n=1}\prod_{i=1}^ma_{ik_i}\det ([e_{k_1},...,e_{k_n}])$$
	p So what is the value of the determinant here?
	p We know that the determinant of the identity matrix is \(1\).
	p We know that the determinant of a matrix with identical columns is \(0\).
	p We know that swapping columns multiplies the determinant by \(-1\).
	p Therefore the determinants where the values of \(k\) are not all unique are \(0\).
	p The determinants of the others are either \(-1\) or \(1\) depending on how many swaps are required to restore to the identity matrix.
	p This is also shown as the Leibni formula.
	p $$\det A = \sum_{\sigma \in S_n}sgn (\sigma )\prod_{i=1}^na_{i,\sigma_i}$$

