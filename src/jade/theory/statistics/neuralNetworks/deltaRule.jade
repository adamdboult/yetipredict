extends ./subSubTemplate.jade
block subSubTitle
	h1
		b Delta rule
block subSubContent
	h3
		b Introduction
	p We want to train the parameters \(\Theta \).
	p We can do this with gradient descent, by working out how much the loss function falls as we change each parameter.
	p The delta rule tells us how to do this.
	h3
		b Initialising parameters
	p We start by randomly initialisng the value of each \(\theta \).
	p We do this to prevent each neuron from moving in sync.

	h3
		b Deriving the rule
	p The error of the network is:
	p \(E=\sum_j\frac{1}{2}(y_j-a_j)^2\)
	p We know that \(a_j=a(\theta x_j)\) and so:
	p \(E=\sum_j\frac{1}{2}(y_j-a(\theta x_j))^2\)
	p We can see the change in error as we change the parameter:
	p \(\frac{\delta E}{\delta \theta_i }=\frac{\delta E}{\delta a_j}\frac{\delta a_j}{\delta z_j}\frac{\delta z_j}{\delta \theta_i}\)
	p \(\frac{\delta E}{\delta \theta_i }=-\sum_j(y_j-a_j)a'(z_j)x_{ij}\)
	h3
		b The delta rule
	p We update the parameters using gradient descent:
	p \(\Delta \theta_i=\alpha \sum_j(y_j-a_j)a'(z_j)x_{ij}\)
	p We can also define \(\delta_i=-\frac{\delta E}{\delta z_j}=\sum_j(y_j-a_j)a'(z_j)\)
	p In this case:
	p \(\Delta \theta_i=\alpha \delta_i x_{ij}\)

