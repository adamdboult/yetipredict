extends ./subSubTemplate.jade
block subSubTitle
	h1
		b Classical principal component analysis
block subSubContent
	h3
		b Introduction
	p Principal component analysis takes a dataset \(X\) with \(m\) variables and returns a principal component matrix \(A\) with size \(m\times k\).
	p Each new dimension is a linear function of the existing data. \(Z=XA\).

	p Each dimension in uncorrelated, and ordered, in order of descending explanation of variability.
	p The problem of principal component analysis is to find these weightings \(A\).
	h3
		b Classical PCA
	p We take the first \(k\) eigenvectors of the covariance matrix, ordered by eigenvalue.
	h3
		b Getting the eigenvectors using SVD
	p We can decompose \(X=U\Sigma A^T\).
	p We can take the eigenvectors from \(A\).
	h3
		b Choosing the number of dimension
	p We can choose \(k\) such that a certain percentage of the variance is retained.

