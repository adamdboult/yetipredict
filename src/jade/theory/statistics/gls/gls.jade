extends ./subSubTemplate.jade
block subSubTitle
	h1
		b The Generalised Least Squares (GLS) estimator
block subSubContent
	h3
		b Introduction
	p We make the same assumptions as OLS.
	p \(\mathbf {y}=\mathbf {X}\theta+\boldsymbol {\epsilon }\)

	p We assume:
	ul
		li \(E[\epsilon |\boldsymbol X]=0\)
		li \(Cov [\epsilon |\boldsymbol X]=\boldsymbol \Omega \)
	h3
		b The GLS estimator
	p GLS estimator is:
	p \(\hat \theta_{GLS} = argmin_b (y-Xb)^T\Omega^{-1}(y-Xb)\)


	p \(\hat \theta_{GLS}=(X^T\Omega ^{-1}X)^{-1}X^T\Omega^{-1}y\)

	p This is the vector that minimises the Mahalanobis distance.

	p This is equivalent to doing OLS on a linearly transformed version of the data.
	h3
		b Identifying \(\Omega \)
	p If \(\Omega \) is known, we can proceed. Generally, however, \(\Omega \) is not known, and so the GLS estimate in infeasible.

