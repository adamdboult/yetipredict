extends ./subSubTemplate.jade
block subSubTitle
	h1
		b Gradient boosting
block subSubContent
	h3
		b Gradient boosting
	p Gradient boosting does not iterative change the weights for the learners. Instead, it trains on different errors.
	p While AdaBoost trains to reduce the absolute error for each weak classifier, gradient boosting trains on the difference between the actual classiffication and the current classification.
	p 
