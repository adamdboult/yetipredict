extends ./subSubTemplate.jade
block subSubTitle
	h1
		b Bayesian optimisation
block subSubContent
	h3
		b Introduction

	p If we have sampled from the hyperparameter space we know something about the shape.

	p Can we use this to inform where we should next look?

	p The shape of the function is \(y=f(\mathbf x)\)

	p We have observations \(\mathbf X\) and \(\mathbf y\).

	p So what's our posterior, \(P(y|\mathbf X, \mathbf y)\)?

	h3
		b Exploration and exploitation

	p The can be a tradeoff between:

	ul
		li Exploring - which gives us a better shape for \(y=f(x)\); and
		li Exploiting - which gives us a better estimate for the global optimum.

	h3
		b The surrogate function

	p We do not know \(y=f(x)\), but we model it as:

	p \(z(x)=y(x)+\epsilon\)

	p We can then maximise \(z\)

	h3	
		b Proposing new candidates

	p We want an algorithm which maps from our history of observations to a new candidate.

	p There are different approaches:
	ul
		li Probability of improvement - Choosing one with the highest chance of a more optimal value
		li Expected improvement - Choosing one with the biggest expected increase in the optimal value
		li Entropy search - choosing one which reduces uncertainty about the global maximum.

