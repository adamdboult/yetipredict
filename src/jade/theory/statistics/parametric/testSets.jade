extends ./subSubTemplate.jade
block subSubTitle
	h1
		b Test sets
block subSubContent
	p overfitting is a risk. Instead we split to test, train. risk of using too many features. more features always improve training score, not necessarily test score.

	p as model gets more complex, both test and train do better. however at some point, test stops doing better, overfitting

	p structural risk minimisation can address this trade off. use test and training sets. train model on train, rate it on test

	p structural minimisation curve has accuracy of boths sets over complexity

	p to avoid overfitting:
	p + reduce numbe of features
	p + do a model selection
	p + use regularisation
	p + do cross validation 

	p can also add validation set
	p can choose other model parameters

	p can do k-fold cross validation. given algo A and dataset D, divide D into k equal sized subsets
	p for each subset, train the model on all other subsets and test on the other subset. average error between folds

	p how to evalute model?
	p confusion matrix. true positve, false positive, false negative, true negative
	p can use this to get
	p accuracy: percentage correct
	p precision: percentage of positive predictions which are correct
	p recall (sensitivity): percentage of poitive cases that were predicted as positive
	p specificity: percentage of negative cases preicated as negative 

	p perceptron: one node neural network. is one or zero depednign if weightd inputs enough. therefore is classiication
	p if error, update weights
	p only works if linearly separable. ie can draw linear line completely separting all inputs

	p neural network has more layers

	p works if data is linear


	p how to treat node inputs: raw, sigmoid, {0,1}
	p for all of these want the cost function have only one solution, like least squares doe. not guaranteed for all
	p for logistic, want to make it convex. loss = -log(f(x)) or -log(1-f(x)) depending on correct y. this is convex

	p how to create node inputs: sigmoid, binary cutoff

