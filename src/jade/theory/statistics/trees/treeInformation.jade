extends ./subSubTemplate.jade
block subSubTitle
	h1
		b Training decision trees with information gain
block subSubContent
	h3
		b Introduction
	p start with all outcomes in same node. then do greedy search: which feature best splits
	p then iterate this
	p for each have node purity, all examples go to a sub branch
	p how to do split? ne which maximises entropy
	p entropy = -\sum_i^n p_i\log_2 p_i
	p gain in entropy = original entropy - weighted by size entropy of each branch


	h3
		b Information gain
	p Information gain ratio
